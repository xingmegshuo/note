{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于神经网络的手写识别，识别数字０－９\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(filename):\n",
    "    data = sio.loadmat(filename)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilizeThetaWeights(L_in,L_out):\n",
    "    epsilon = np.sqrt(6)/np.sqrt(L_in+L_out)\n",
    "    return np.random.rand(L_out,L_in)*2*epsilon-epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(X,Theta1,Theta2,y,num_labels,m,_lambda):\n",
    "    a1 = np.vstack((np.ones(m),X.T)).T\n",
    "    a2 = sigmoid(np.dot(a1,Theta1.T))\n",
    "    a2 = np.vstack((np.ones(m),a2.T)).T\n",
    "    a3 = sigmoid(np.dot(a2,Theta2.T))\n",
    "    y = np.tile((np.arange(num_labels)+1)%10,(m,1)) == np.tile(y,(1,num_labels))\n",
    "    regTheta1 = Theta1[:,1:]\n",
    "    regTheta2 = Theta2[:,1:]\n",
    "    \n",
    "    J = -np.sum(y*np.log(a3)+(1-y)*np.log(1-a3))/m+_lambda*np.sum(regTheta1*regTheta1)/m/2+_lambda*np.sum(regTheta2*regTheta2)/m/2\n",
    "    \n",
    "    delta2 = np.zeros(Theta1.shape)\n",
    "    delta3 = np.zeros(Theta2.shape)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a1_ = a1[i];a2_=a2[i];a3_=a3[i]\n",
    "        d3 = a3_-y[i]\n",
    "        d2 = np.dot(d3,Theta2)*sigmoidGradient(np.append(1,np.dot(a1_,Theta1.T)))\n",
    "        delta2 = delta2 + np.dot(d2[1:].reshape(-1,1),a1_.reshape(1,-1))\n",
    "        delta3 = delta3 + np.dot(d3.reshape(-1,1),a2_.reshape(1,-1))\n",
    "        Theta1_grad = np.zeros(Theta1.shape)\n",
    "        Theta2_grad = np.zeros(Theta2.shape)\n",
    "        Theta1_grad[:,0] = delta2[:,0]/m\n",
    "        Theta2_grad[:,0] = delta3[:,0]/m\n",
    "        Theta1_grad[:,1:] = delta2[:,1:]/m + _lambda*regTheta1/m\n",
    "        Theta2_grad[:,1:] = delta3[:,1:]/m + _lambda*regTheta2/m\n",
    "    return J,Theta1_grad,Theta2_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(Theta1,Theta2,X,y,num_labels,m,_lambda,iter_num,learning_rate):\n",
    "    i = 0\n",
    "    J_list = []\n",
    "    J,Theta1_grad,Theta2_grad = nnCostFunction(X,Theta1,Theta2,y,num_labels,m,_lambda)\n",
    "    while i < iter_num:\n",
    "        Theta1 = Theta1 - learning_rate*Theta1_grad\n",
    "        Theta2 = Theta2 - learning_rate*Theta2_grad\n",
    "        J,Theta1_grad,Theta2_grad = nnCostFunction(X,Theta1,Theta2,y,num_labels,m,_lambda)\n",
    "        J_list.append(J)\n",
    "        i+=1\n",
    "        print('迭代:',i,'->','J:',J)\n",
    "    return J_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Theta1,Theta2,X,m):\n",
    "    a1 = np.vstack((np.ones(m),X.T)).T\n",
    "    a2 = sigmoid(np.dot(a1,Theta1.T))\n",
    "    a2 = np.vstack((np.ones(m),a2.T)).T\n",
    "    a3 = sigmoid(np.dot(a2,Theta2.T))\n",
    "    return np.argmax(a3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401, 25) (10, 26) (3000, 400)\n",
      "迭代: 1 -> J: 0.39258268719046385\n",
      "迭代: 2 -> J: 0.38172657348681144\n",
      "迭代: 3 -> J: 0.3753078961624206\n",
      "迭代: 4 -> J: 0.3707278871588442\n",
      "迭代: 5 -> J: 0.36715039715537046\n",
      "迭代: 6 -> J: 0.3641951317551498\n",
      "迭代: 7 -> J: 0.3616612280704919\n",
      "迭代: 8 -> J: 0.35943150146939135\n",
      "迭代: 9 -> J: 0.35743229738407983\n",
      "迭代: 10 -> J: 0.35561449900377695\n",
      "迭代: 11 -> J: 0.3539437319768687\n",
      "迭代: 12 -> J: 0.3523949593629182\n",
      "迭代: 13 -> J: 0.3509493302623222\n",
      "迭代: 14 -> J: 0.349592253636778\n",
      "迭代: 15 -> J: 0.34831217167967626\n",
      "迭代: 16 -> J: 0.34709974990848724\n",
      "迭代: 17 -> J: 0.34594732487838037\n",
      "迭代: 18 -> J: 0.3448485166719958\n",
      "迭代: 19 -> J: 0.34379794996119467\n",
      "迭代: 20 -> J: 0.34279104863338644\n",
      "迭代: 21 -> J: 0.34182388149722176\n",
      "迭代: 22 -> J: 0.34089304427839356\n",
      "迭代: 23 -> J: 0.33999556792593477\n",
      "迭代: 24 -> J: 0.3391288463552326\n",
      "迭代: 25 -> J: 0.3382905787914914\n",
      "迭代: 26 -> J: 0.3374787232495938\n",
      "迭代: 27 -> J: 0.3366914586249713\n",
      "迭代: 28 -> J: 0.33592715352583036\n",
      "迭代: 29 -> J: 0.33518434044208734\n",
      "迭代: 30 -> J: 0.3344616941818147\n",
      "迭代: 31 -> J: 0.3337580137513588\n",
      "迭代: 32 -> J: 0.3330722070373311\n",
      "迭代: 33 -> J: 0.3324032777853955\n",
      "迭代: 34 -> J: 0.3317503144747139\n",
      "迭代: 35 -> J: 0.3311124807667596\n",
      "迭代: 36 -> J: 0.3304890072691843\n",
      "迭代: 37 -> J: 0.32987918440396485\n",
      "迭代: 38 -> J: 0.3292823562073992\n",
      "迭代: 39 -> J: 0.3286979149200523\n",
      "迭代: 40 -> J: 0.3281252962492313\n",
      "迭代: 41 -> J: 0.32756397520633457\n",
      "迭代: 42 -> J: 0.327013462437469\n",
      "迭代: 43 -> J: 0.32647330097884636\n",
      "迭代: 44 -> J: 0.3259430633792339\n",
      "迭代: 45 -> J: 0.32542234914062323\n",
      "迭代: 46 -> J: 0.3249107824356471\n",
      "迭代: 47 -> J: 0.3244080100664064\n",
      "迭代: 48 -> J: 0.3239136996344974\n",
      "迭代: 49 -> J: 0.32342753789632744\n",
      "迭代: 50 -> J: 0.32294922928143344\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 6 ... 9 9 9]\n",
      "[[6]\n",
      " [6]\n",
      " [6]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "\n",
      "Training Set Accuracy: 97.400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if_use_ex4weight = 1\n",
    "input_layer_size = 401\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "iter_num = 50\n",
    "learning_rate = 2\n",
    "_lambda = 1\n",
    "data = loadData('ex4data1.mat')\n",
    "present = 0.6\n",
    "X_ = data['X']\n",
    "y_ = data['y']%10\n",
    "# print(len(X_)*present)\n",
    "X = X_[:int(len(X_)*present)]\n",
    "y = y_[:len(X)]\n",
    "predict_x = X_[len(X):]\n",
    "predict_y = y_[len(X):]\n",
    "m = X.shape[0]\n",
    "Theta1_L_in = 401\n",
    "Theta1_L_out = 25\n",
    "Theta2_L_in = 26\n",
    "Theta2_L_out = 10\n",
    "if if_use_ex4weight == 0:\n",
    "    Theta1 = initilizeThetaWeights(Theta1_L_in,Theta1_L_out)\n",
    "    Theta2 = initilizeThetaWeights(Theta2_L_in,Theta2_L_out)\n",
    "else:\n",
    "    data_weights = loadData('ex4weights.mat')\n",
    "    Theta1 = data_weights['Theta1']\n",
    "    Theta2 = data_weights['Theta2']\n",
    "print(Theta1.T.shape,Theta2.shape,X.shape)\n",
    "J_list = gradientDescent(Theta1,Theta2,X,y,num_labels,m,_lambda,iter_num,learning_rate)\n",
    "J_list = np.asarray(J_list).reshape(1,iter_num)[0]\n",
    "plt.plot(np.arange(0,iter_num,1),np.array(J_list).reshape(iter_num,1),'-r')\n",
    "plt.show()\n",
    "pred = (predict(Theta1,Theta2,predict_x,predict_x.shape[0])+1)%10\n",
    "print(pred)\n",
    "print(predict_y)\n",
    "print('\\nTraining Set Accuracy: %f\\n'%(np.mean(np.double(pred == predict_y.T)) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1: [[-0.8113182   1.4845988   0.06532937 ...  0.32066926  1.132831\n",
      "  -2.2782571 ]\n",
      " [ 0.48281202 -1.3127087   0.35685033 ... -0.7706542  -0.74624157\n",
      "  -0.28195325]\n",
      " [-1.9588155  -0.3376107   1.0301983  ... -0.30744898 -0.7669297\n",
      "  -0.28710833]\n",
      " ...\n",
      " [ 1.0998409   0.03693226  0.44521236 ... -0.03898062  0.29257604\n",
      "  -0.31505573]\n",
      " [-0.798138    1.0684257   1.1696315  ...  0.21108748  0.00749771\n",
      "   0.01269779]\n",
      " [-0.02291953 -0.1323976  -0.22013924 ...  1.0481157  -1.55838\n",
      "   1.8832947 ]]\n",
      "w2: [[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]\n",
      " [-2.4427042 ]\n",
      " [ 0.0992484 ]\n",
      " [ 0.5912243 ]\n",
      " [ 0.59282297]\n",
      " [-2.1229296 ]\n",
      " [-0.72289723]\n",
      " [-0.05627038]\n",
      " [ 0.6435448 ]\n",
      " [-0.26432407]\n",
      " [ 1.8566332 ]\n",
      " [ 0.5678417 ]\n",
      " [-0.3828359 ]\n",
      " [-1.4853433 ]\n",
      " [ 1.2617711 ]\n",
      " [-0.02530608]\n",
      " [-0.2646297 ]\n",
      " [ 1.5328138 ]\n",
      " [-1.7429771 ]\n",
      " [-0.43789294]\n",
      " [-0.56601   ]\n",
      " [ 0.32066926]\n",
      " [ 1.132831  ]\n",
      " [-2.2782571 ]]\n",
      "After 0 training step(s), cross entropy on all data is 0.122805\n",
      "After 1000 training step(s), cross entropy on all data is 0.122805\n",
      "After 2000 training step(s), cross entropy on all data is 0.122805\n",
      "After 3000 training step(s), cross entropy on all data is 0.122805\n",
      "After 4000 training step(s), cross entropy on all data is 0.122805\n",
      "After 5000 training step(s), cross entropy on all data is 0.122805\n",
      "After 6000 training step(s), cross entropy on all data is 0.122805\n",
      "After 7000 training step(s), cross entropy on all data is 0.122805\n",
      "After 8000 training step(s), cross entropy on all data is 0.122805\n",
      "After 9000 training step(s), cross entropy on all data is 0.122805\n",
      "\n",
      "Training Set Accuracy: 0.00\n",
      "\n",
      "\n",
      "\n",
      "w1: [[-0.8113182   1.4845988   0.06532937 ...  0.32066926  1.132831\n",
      "  -2.2782571 ]\n",
      " [ 0.48281202 -1.3127087   0.35685033 ... -0.7706542  -0.74624157\n",
      "  -0.28195325]\n",
      " [-1.9588155  -0.3376107   1.0301983  ... -0.30744898 -0.7669297\n",
      "  -0.28710833]\n",
      " ...\n",
      " [ 1.0998409   0.03693226  0.44521236 ... -0.03898062  0.29257604\n",
      "  -0.31505573]\n",
      " [-0.798138    1.0684257   1.1696315  ...  0.21108748  0.00749771\n",
      "   0.01269779]\n",
      " [-0.02291953 -0.1323976  -0.22013924 ...  1.0481157  -1.55838\n",
      "   1.8832947 ]]\n",
      "w2: [[-0.6051807 ]\n",
      " [ 1.5020797 ]\n",
      " [ 0.06697758]\n",
      " [-2.4383516 ]\n",
      " [ 0.06039352]\n",
      " [ 0.40598813]\n",
      " [ 0.8006379 ]\n",
      " [-2.077082  ]\n",
      " [-0.75737137]\n",
      " [-0.23265076]\n",
      " [ 0.77291036]\n",
      " [-0.05817982]\n",
      " [ 2.0681796 ]\n",
      " [ 0.45419896]\n",
      " [-0.30987054]\n",
      " [-1.6815263 ]\n",
      " [ 1.2391762 ]\n",
      " [ 0.0135504 ]\n",
      " [-0.47582182]\n",
      " [ 1.7393823 ]\n",
      " [-1.7073    ]\n",
      " [-0.6316968 ]\n",
      " [-0.62576234]\n",
      " [ 0.32868856]\n",
      " [ 1.3372    ]\n",
      " [-2.272416  ]]\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "batch_size=10\n",
    "theta1=tf.Variable(tf.random_normal([400,26],stddev=1,seed=1))\n",
    "theta2=tf.Variable(tf.random_normal([26, 1], stddev=1, seed=1))\n",
    "x_a=tf.placeholder(tf.float32,shape=(None,400))\n",
    "y_a=tf.placeholder(tf.float32,shape=(None,1))\n",
    "a=tf.matmul(x_a,theta1)\n",
    "y_n=tf.matmul(a,theta2)\n",
    "prection=tf.nn.tanh(y_n)\n",
    "\n",
    "cross_entropy=-tf.reduce_mean(y_a*tf.log(tf.clip_by_value(y_n,1e-10,1.0)))\n",
    "train_step=tf.train.AdamOptimizer(learning_rate=0.01).minimize(cross_entropy)\n",
    "STEPS = 10000\n",
    "with tf.Session() as sess:\n",
    "    init_op=tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    # 输出目前（未经训练）的参数取值。\n",
    "    print(\"w1:\", sess.run(theta1))\n",
    "    print(\"w2:\", sess.run(theta2))\n",
    "#     print(\"\\n\")\n",
    "    for i in range(STEPS):\n",
    "        start = (i * batch_size) % len(X)\n",
    "        end = (i * batch_size) % len(X) + batch_size\n",
    "        sess.run(train_step, feed_dict={x_a: X[start:end], y_a: y[start:end]})\n",
    "        if i % 1000 == 0:\n",
    "            total_cross_enpy = sess.run(cross_entropy, feed_dict={x_a: X, y_a: y})\n",
    "            print(\"After %d training step(s), cross entropy on all data is %g\" % (i, total_cross_entropy))\n",
    "            # 输出训练后的参数取值。tro\n",
    "    prediction_value = sess.run(prection,feed_dict={x_a:predict_x})\n",
    "    print('\\nTraining Set Accuracy: %.2f\\n'%(np.mean(np.double(prediction_value == predict_y)) * 100))\n",
    "    print(\"\\n\")\n",
    "    print(\"w1:\", sess.run(theta1))\n",
    "    print(\"w2:\", sess.run(theta2))\n",
    "    print(prediction_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[1]])\n",
    "x = tf.placeholder(tf.float32,[1,1])\n",
    "w = tf.Variable(0,dtype=tf.float32)\n",
    "cost = x[0][0]-w**2\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "# session.run(train)\n",
    "# print(session.run(w))\n",
    "for i in range(1500):\n",
    "    session.run(train,feed_dict={x:data})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "intermed = input2+input3\n",
    "mul = intermed * input1\n",
    "result = session.run([mul,intermed])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.44579133],\n",
      "       [1.0637012 ]], dtype=float32), array([-0.49301356], dtype=float32)]\n",
      "\n",
      "Training Set Accuracy: 95.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_data = np.float32(np.random.rand(100,2))\n",
    "y_data = np.dot(x_data,[[0.1],[0.2]])+0.3\n",
    "y_data[y_data>=0.5]=1\n",
    "y_data[y_data<0.5]=0\n",
    "predict_y=y_data[60:]\n",
    "x = tf.placeholder(tf.float32,shape=(None,2))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "w = tf.Variable(tf.random_uniform([2,1],0,0))\n",
    "y = tf.matmul(x,w) +b\n",
    "loss = tf.reduce_mean(tf.square(y-y_data[:60]))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "    for step in range(0,500):\n",
    "        sess.run(train,feed_dict={x:x_data[:60]})  \n",
    "    print(sess.run([w,b]))\n",
    "    predict=sess.run(y,feed_dict={x:x_data[60:]})\n",
    "    predict[predict>=0.5]=1\n",
    "    predict[predict<0.5]=0\n",
    "    print('\\nTraining Set Accuracy: %.2f\\n'%(np.mean(np.double(predict == predict_y)) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
